defaults:
  - _features.yaml

_target_: null

data_dir: ${paths.data_dir}

# Number of classes must be specified to help instantiating the model.
# Concretely, num_classes here will be passed to the DataModule and the
# Dataset upon hydra.utils.instantiate. But it will likely be ignored by
# those. Specifying num_classes in the data config actually allows the
# model config to capture it and assign the proper model output size by
# config interpolation
num_classes: ???

# I/O parameters
save_y_to_csr: True  # save 'y' label histograms using a custom CSR format to save memory and I/O time
save_pos_dtype: 'float32'  # dtype to which 'pos' will be saved on disk
save_fp_dtype: 'float16'  # dtype to which all other floating point tensors will be saved to disk
in_memory: False

# Disk memory
# Set lite_preprocessing to only preprocess and save to disk features
# strictly needed for training, to save disk memory. If False, all
# supported point, segment features will be computed. This can be useful
# if you are experimenting with various feature combinations and do not
# want preprocessing to start over whenever testing a new combination
# If True, lite_preprocessing alleviate disk memory use and makes I/O
# faster, hence faster training and inference
lite_preprocessing: True

# GPU memory
# The following parameters are not the only ones affecting GPU memory.
# Several strategies can be deployed to mitigate memory impact, from
# batch construction to architecture size. However, these are good
# safeguard settings as a last resort to prevent our base model from OOM
# a 32G GPU at training time. May be adapted to other GPUs, models and
# training procedures
max_num_nodes: 50000
max_num_edges: 1000000

# Transforms
pre_transform: null
train_transform: null
val_transform: null
test_transform: null
on_device_train_transform: null
on_device_val_transform: null
on_device_test_transform: null

# Test-time augmentation
tta_runs: null
tta_val: False

# Produce submission data if test is true
submit: False

# DataLoader parameters. Would be good to have them live in another file
dataloader:
    batch_size: 4
    num_workers: 4
    pin_memory: True
    persistent_workers: True
